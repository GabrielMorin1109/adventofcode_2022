#
# ggplot(Valprop.S, aes(x = num.vp,y = vp))+
#   geom_line()+geom_point()
# ```
# ```{r}
# Valprop.R <- data.frame(num.vp=seq_along(SpecDec.R$values),vp=SpecDec.R$values)
# transform(Valprop.R, cumFreq = cumsum(vp), relative = cumsum(vp)/sum(vp))
#
# ggplot(Valprop.R, aes(x = num.vp,y = vp))+
#   geom_line()+geom_point()
SpecDec.S$values
SpecDec.S$values
SpecDec.R$values
require(factoextra)
Fish.pca.S <- prcomp(Fish, center = TRUE, scale = FALSE) # PCA on covariance matrix
factoextra::fviz_contrib(Fish.pca.R, choice = "var", axes = 1, top = 10)
Fish.pca.R
Fish.pca.S <- prcomp(Fish, center = TRUE, scale = FALSE) # PCA on covariance matrix
Fish.pca.S
Fish.pca.S <- prcomp(Fish, center = TRUE, scale = FALSE) # PCA on covariance matrix
factoextra::fviz_contrib(Fish.pca.R, choice = "var", axes = 1, top = 10)
factoextra::fviz_contrib(Fish.pca.S, choice = "var", axes = 1, top = 10)
factoextra::fviz_pca_ind(Fish.pca.R)
factoextra::fviz_pca_ind(Fish.pca.S)
Grps <- as.factor(rownames(Fish))
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps, addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
Grps
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps, addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
Fish.pca.S
Fish.pca.S$rotation
Fish.pca.S$center
Fish.pca.S$scale
Fish.pca.S$x
Fish.pca.S
factoextra::fviz_pca_ind(Fish.pca.S)
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps, #addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps,
#addEllipses=TRUE,
ellipse.level=0.95, palette = "Dark2")
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps,
#addEllipses=TRUE,
ellipse.level=0.95, palette = "Dark2")
factoextra::fviz_pca_ind(Fish.pca.S)
rownames(Fish) <- NULL
Fish.pca.S <- prcomp(Fish, center = TRUE, scale = FALSE) # PCA on covariance matrix
Fish.pca.S
factoextra::fviz_pca_ind(Fish.pca.S)
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps,
addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
factoextra::fviz_pca_ind(Fish.pca.S)
factoextra::fviz_pca_biplot(Fish.pca.S)
factoextra::fviz_pca_biplot(Fish.pca.S)
factoextra::fviz_pca_ind(Fish.pca.S)
factoextra::fviz_pca_ind(Fish.pca.S, label="none", habillage=Grps,
addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
FtB2
Grps <- as.factor(rownames(FtB2))
factoextra::fviz_pca_ind(FtB2.pca, label="none", habillage=Grps,
addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
Grps <- as.factor(rownames(FtB2))
FtB2.pca <- stats::prcomp(FtB2, center = TRUE, scale = TRUE) # PCA on correlation matrix
rownames(FtB2) <- NULL
Grps <- Grps.FtB2
Grps.FtB2 <- Grps
Grps.FtB2 <- as.factor(rownames(FtB2))
rownames(FtB2) <- NULL
FtB2.pca <- stats::prcomp(FtB2, center = TRUE, scale = TRUE) # PCA on correlation matrix
factoextra::fviz_pca_ind(FtB2.pca, label="none", habillage=Grps,
addEllipses=TRUE, ellipse.level=0.95, palette = "Dark2")
factoextra::fviz_contrib(FtB2.pca, choice = "var", axes = 1, top = 10)
require(data.table)
# path to wd
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
library(rbenchmark)
install.packages("rbenchmark")
library(rbenchmark)
benchmark("Day1" = {
require(data.table)
# path to wd
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
})
getwd()
benchmark("Day1" = {
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.R")
})
benchmark("Day1" = {
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.R")
})
library(microbenchmark)
install.packages("microbenchmark")
mbm <- microbenchmark("Day1" = {
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.R")
})
library(microbenchmark)
mbm <- microbenchmark("Day1" = {
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.R")
})
plot(microbenchmark)
library(ggplot2)
autoplot(mbm)
mbm
#!/usr/bin/env Rscript
require(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
autoplot(mbm)
mbm
mbm
microbenchmark("Day1" = {
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.py")
}); mbm
mbm
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.R")
mbm <- rbenchmark("Day1" = {
source("/home/gabriel/Documents/Github/adventofcode_2022/Day1/puzzle1.R")
}); mbm
Day1
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
Day1()
mbm <- rbenchmark("Day1" = {
Day1()
}); mbm
mbm <- benchmark("Day1" = {
Day1()
}); mbm
microbenchmark("Day1" = {
Day1()
}); mbm
source("~/Documents/Github/adventofcode_2022/Day1/puzzle1.R", echo=TRUE)
rbenchmark::benchmark("Day1" = {
Day1()
})
microbenchmark::microbenchmark("Day1" = {
Day1()
})
microbenchmark::microbenchmark("Day1" = {
Day1()
})
# BENCHMARK:
rbenchmark::benchmark("Day1" = {
Day1()
})
microbenchmark::microbenchmark("Day1" = {
Day1()
})
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
library(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
# library(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
# library(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
# library(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
# library(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(Elf)) + 1]
# sum by group
tmp <- dd[, .(cumElf = sum(Elf, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumElf,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
#!/usr/bin/env Rscript
Day1 <- function(){
# library(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
detach("package:data.table", unload = TRUE)
library(data.table)
getDTthreads
getDTthreads()
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
data.table::setDTthreads(threads = 2)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
data.table::setDTthreads(threads = 12)
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
data.table::setDTthreads(threads = 2)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
data.table::setDTthreads(threads = 12)
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
data.table::setDTthreads(threads = 24)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
data.table::setDTthreads(threads = 12)
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
data.table::setDTthreads(threads = 1)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
data.table::setDTthreads(threads = 12)
#!/usr/bin/env Rscript
Day1 <- function(){
require(data.table)
data.table::setDTthreads(threads = 2)
# path to wd # path.wd <- "/home/gabriel/Documents/Github/adventofcode_2022/Day1/" # for benchmark
path.wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(path.wd)
# read data:
dd <- data.table::fread("input.txt")
# data.table::setnames(dd, new = 'Elf') # for better reading
# Create a group column exploiting the rows with NA
dd[, Grp := cumsum(is.na(V1)) + 1]
# sum by group
tmp <- dd[, .(cumV1 = sum(V1, na.rm = TRUE)), Grp]
tmp[, {
.n = .N # number of rows
.range = .n:(.n - 2) # save in memory the select range to limit the number of copies
.n.largest = sort(cumV1,  partial = .range)[.range] # partial sorting is faster than normal sorting
.(sol1 = .n.largest[1], sol2 = sum(.n.largest)) # final solution:
}]
}
# BENCHMARK:
microbenchmark::microbenchmark("Day1" = {
Day1()
})
data.table::setDTthreads(threads = 12)
